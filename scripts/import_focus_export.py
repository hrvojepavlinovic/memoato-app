#!/usr/bin/env python3

from __future__ import annotations

import csv
import json
import sys
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any


def _parse_ts(s: str | None) -> datetime | None:
    if s is None:
        return None
    s = s.strip()
    if s == "" or s.lower() == "null" or s == "-":
        return None
    # Export uses `YYYY-MM-DDTHH:MM:SS.mmm` without timezone.
    # Treat it as local/naive and store as-is (Postgres `timestamp`).
    try:
        return datetime.fromisoformat(s)
    except ValueError:
        return None


def _sql_str(value: str | None) -> str:
    if value is None:
        return "NULL"
    return "'" + value.replace("'", "''") + "'"


def _sql_int(value: str | None) -> str:
    if value is None:
        return "NULL"
    value = value.strip()
    if value == "" or value.lower() == "null" or value == "-":
        return "NULL"
    return str(int(value))


def _sql_float(value: str | None) -> str:
    if value is None:
        return "NULL"
    value = value.strip()
    if value == "" or value.lower() == "null" or value == "-":
        return "NULL"
    return str(float(value))


def _sql_ts(value: datetime | None) -> str:
    if value is None:
        return "NULL"
    # Keep full precision; Postgres accepts ISO without tz for timestamp.
    return _sql_str(value.isoformat(timespec="milliseconds"))


def _sql_date_from_ts(ts: datetime | None) -> str:
    if ts is None:
        return "NULL"
    return _sql_str(ts.date().isoformat())


def _sql_json(value: str | None) -> str:
    if value is None:
        return "NULL"
    value = value.strip()
    if value == "" or value.lower() == "null" or value == "-":
        return "NULL"
    try:
        parsed = json.loads(value)
    except json.JSONDecodeError:
        # Store raw string as JSON string.
        parsed = value
    return _sql_str(json.dumps(parsed, ensure_ascii=False)) + "::jsonb"


@dataclass(frozen=True)
class ExportPaths:
    activities_csv: Path
    sessions_csv: Path
    notes_csv: Path


def _detect_export_dir(arg: str | None) -> Path:
    if arg:
        return Path(arg)

    imports = Path("imports")
    candidates = sorted(
        (p for p in imports.glob("export_*") if p.is_dir()),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    if not candidates:
        raise SystemExit("No export dir found under ./imports/export_* (pass a path).")
    return candidates[0]


def _load_paths(export_dir: Path) -> ExportPaths:
    activities = export_dir / "activities.csv"
    sessions = export_dir / "sessions.csv"
    notes = export_dir / "notes.csv"
    missing = [p.name for p in (activities, sessions, notes) if not p.is_file()]
    if missing:
        raise SystemExit(f"Missing files in {export_dir}: {', '.join(missing)}")
    return ExportPaths(activities, sessions, notes)


def _emit_preamble() -> None:
    now = datetime.now(timezone.utc).isoformat(timespec="seconds")
    print("-- Generated by scripts/import_focus_export.py")
    print(f"-- Generated at {now}")
    print("BEGIN;")
    print("SET LOCAL client_min_messages = warning;")
    print("SET LOCAL statement_timeout = '5min';")
    print("")


def _emit_categories(paths: ExportPaths) -> None:
    with paths.activities_csv.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_source_id = (row.get("id") or "").strip()
            source_id = _sql_int(raw_source_id)
            stable_id = _sql_str(f"focus_cat_{raw_source_id}")
            title = _sql_str(row.get("title"))
            type_ = _sql_str(row.get("type"))
            kind = _sql_str(row.get("kind"))
            target_count = _sql_int(row.get("count"))
            period = _sql_str(row.get("period"))
            target_duration = _sql_int(row.get("target_duration"))
            created_at = _sql_ts(_parse_ts(row.get("created_at")))
            archived_at = _sql_ts(_parse_ts(row.get("archived_at")))

            print(
                "INSERT INTO \"Category\" (\"id\", \"source\", \"sourceId\", \"title\", \"type\", \"kind\", "
                "\"targetCount\", \"period\", \"targetDuration\", \"sourceCreatedAt\", \"sourceArchivedAt\", \"updatedAt\") "
                f"VALUES ({stable_id}, 'focus', {source_id}, {title}, {type_}, {kind}, {target_count}, {period}, {target_duration}, "
                f"{created_at}, {archived_at}, CURRENT_TIMESTAMP) "
                "ON CONFLICT (\"source\", \"sourceId\") DO UPDATE SET "
                "\"title\"=EXCLUDED.\"title\", "
                "\"type\"=EXCLUDED.\"type\", "
                "\"kind\"=EXCLUDED.\"kind\", "
                "\"targetCount\"=EXCLUDED.\"targetCount\", "
                "\"period\"=EXCLUDED.\"period\", "
                "\"targetDuration\"=EXCLUDED.\"targetDuration\", "
                "\"sourceCreatedAt\"=EXCLUDED.\"sourceCreatedAt\", "
                "\"sourceArchivedAt\"=EXCLUDED.\"sourceArchivedAt\", "
                "\"updatedAt\"=CURRENT_TIMESTAMP;"
            )
    print("")


def _load_activity_titles(paths: ExportPaths) -> dict[int, str]:
    titles: dict[int, str] = {}
    with paths.activities_csv.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_id = (row.get("id") or "").strip()
            raw_title = (row.get("title") or "").strip()
            if not raw_id or raw_id.lower() == "null" or raw_id == "-":
                continue
            try:
                titles[int(raw_id)] = raw_title
            except ValueError:
                continue
    return titles


def _emit_sessions(paths: ExportPaths, activity_titles: dict[int, str]) -> None:
    with paths.sessions_csv.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_source_id = (row.get("id") or "").strip()
            source_id = _sql_int(raw_source_id)
            stable_id = _sql_str(f"focus_session_{raw_source_id}")
            raw_activity_id = (row.get("activity_id") or "").strip()
            activity_id_sql = _sql_int(raw_activity_id)

            created_at = _parse_ts(row.get("created_at"))
            finished_at = _parse_ts(row.get("finished_at"))
            occurred_at = finished_at or created_at
            occurred_at_sql = _sql_ts(occurred_at)
            occurred_on_sql = _sql_date_from_ts(occurred_at)

            data_raw = row.get("data")
            amount_raw = row.get("amount")
            amount = _sql_float(amount_raw)
            duration = _sql_int(row.get("duration"))
            data = _sql_json(data_raw)

            if amount == "NULL" and data_raw:
                try:
                    parsed = json.loads(data_raw)
                except json.JSONDecodeError:
                    parsed = None
                if isinstance(parsed, dict) and "progress" in parsed:
                    progress = parsed.get("progress")
                    if isinstance(progress, (int, float, str)) and str(progress).strip() != "":
                        try:
                            amount = str(float(progress))
                        except ValueError:
                            pass

            raw_text_val: str | None = None
            try:
                activity_id_int = int(raw_activity_id)
            except ValueError:
                activity_id_int = None
            if activity_id_int is not None:
                title = activity_titles.get(activity_id_int)
                if title:
                    raw_amount = None if amount == "NULL" else amount
                    raw_text_val = f"{title} {raw_amount}".strip() if raw_amount else title
            raw_text = _sql_str(raw_text_val) if raw_text_val is not None else "NULL"

            print(
                "INSERT INTO \"Event\" (\"id\", \"source\", \"kind\", \"sourceId\", \"categoryId\", \"rawText\", "
                "\"amount\", \"duration\", \"data\", \"sourceCreatedAt\", \"sourceFinishedAt\", "
                "\"occurredAt\", \"occurredOn\", \"updatedAt\") "
                "VALUES ("
                f"{stable_id}, 'focus', 'SESSION', {source_id}, "
                f"(SELECT \"id\" FROM \"Category\" WHERE \"source\"='focus' AND \"sourceId\"={activity_id_sql}), "
                f"{raw_text}, {amount}, {duration}, {data}, {_sql_ts(created_at)}, {_sql_ts(finished_at)}, "
                f"{occurred_at_sql}, {occurred_on_sql}, CURRENT_TIMESTAMP) "
                "ON CONFLICT (\"source\", \"kind\", \"sourceId\") DO UPDATE SET "
                "\"categoryId\"=EXCLUDED.\"categoryId\", "
                "\"rawText\"=EXCLUDED.\"rawText\", "
                "\"amount\"=EXCLUDED.\"amount\", "
                "\"duration\"=EXCLUDED.\"duration\", "
                "\"data\"=EXCLUDED.\"data\", "
                "\"sourceCreatedAt\"=EXCLUDED.\"sourceCreatedAt\", "
                "\"sourceFinishedAt\"=EXCLUDED.\"sourceFinishedAt\", "
                "\"occurredAt\"=EXCLUDED.\"occurredAt\", "
                "\"occurredOn\"=EXCLUDED.\"occurredOn\", "
                "\"updatedAt\"=CURRENT_TIMESTAMP;"
            )
    print("")


def _emit_notes(paths: ExportPaths) -> None:
    with paths.notes_csv.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_source_id = (row.get("id") or "").strip()
            source_id = _sql_int(raw_source_id)
            stable_id = _sql_str(f"focus_note_{raw_source_id}")
            note = _sql_str(row.get("note"))

            created_at = _parse_ts(row.get("created_at"))
            occurred_at_sql = _sql_ts(created_at)
            occurred_on_sql = _sql_date_from_ts(created_at)

            # notes.csv can optionally point at session/activity, but export has nulls.
            activity_id_sql = _sql_int(row.get("activity_id"))

            print(
                "INSERT INTO \"Event\" (\"id\", \"source\", \"kind\", \"sourceId\", \"categoryId\", \"rawText\", "
                "\"sourceCreatedAt\", \"occurredAt\", \"occurredOn\", \"updatedAt\") "
                "VALUES ("
                f"{stable_id}, 'focus', 'NOTE', {source_id}, "
                f"(SELECT \"id\" FROM \"Category\" WHERE \"source\"='focus' AND \"sourceId\"={activity_id_sql}), "
                f"{note}, {_sql_ts(created_at)}, {occurred_at_sql}, {occurred_on_sql}, CURRENT_TIMESTAMP) "
                "ON CONFLICT (\"source\", \"kind\", \"sourceId\") DO UPDATE SET "
                "\"categoryId\"=EXCLUDED.\"categoryId\", "
                "\"rawText\"=EXCLUDED.\"rawText\", "
                "\"sourceCreatedAt\"=EXCLUDED.\"sourceCreatedAt\", "
                "\"occurredAt\"=EXCLUDED.\"occurredAt\", "
                "\"occurredOn\"=EXCLUDED.\"occurredOn\", "
                "\"updatedAt\"=CURRENT_TIMESTAMP;"
            )
    print("")


def _emit_commit() -> None:
    print("COMMIT;")


def main(argv: list[str]) -> int:
    export_dir = _detect_export_dir(argv[1] if len(argv) > 1 else None)
    paths = _load_paths(export_dir)
    activity_titles = _load_activity_titles(paths)

    _emit_preamble()
    _emit_categories(paths)
    _emit_sessions(paths, activity_titles)
    _emit_notes(paths)
    _emit_commit()
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))
